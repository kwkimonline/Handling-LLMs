{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of using of OpenAI's GPT through the API\n",
    "\n",
    "#### Writer\n",
    "    Kunwoong Kim\n",
    "\n",
    "#### Created / Last edited\n",
    "    2023.06.21 / 2023.06.21\n",
    "\n",
    "#### Notes\n",
    "    Please be aware of the billing associated with using OpenAI's API!\n",
    "    This notebook is written based on:\n",
    "\n",
    "<https://www.indiehackers.com/post/how-to-fine-tune-a-gpt-3-model-using-python-with-your-own-data-for-improved-performance-198dfe51d6>\n",
    "\n",
    "<https://www.articulatepython.com/blog/finetune-openai-models>\n",
    "\n",
    "<https://www.datacamp.com/tutorial/fine-tuning-gpt-3-using-the-open-ai-api-and-python>\n",
    "\n",
    "<https://passwd.tistory.com/entry/Python-OpenAI-API-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "OpenAI API: create your API key\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "# API key\n",
    "openai.api_key = 'YOUR-API-KEY' # for sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last prompt: Where was it played?\n",
      "Response: The Korean Series in 1999 was played at Mokdong Baseball Stadium in Seoul, South Korea.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' [2] DIY '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "ChatGPT usage examples\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "\"\"\" [1] Chat completion \"\"\"\n",
    "example_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a kind assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the Korean Series in 1999?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hanhwa Eagles won the Korean Series in 1999.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=example_messages\n",
    "    )\n",
    "response = completion.choices[0].message.content\n",
    "print(f'The last prompt: {example_messages[-1][\"content\"]}')\n",
    "print(f'Response: {response}')\n",
    "\n",
    "\"\"\" [2] DIY \"\"\"\n",
    "# TODO: Do it yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "ChatGPT fine-tuning\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "\"\"\" Configuration \"\"\"\n",
    "# model engine\n",
    "model = 'davinci'\n",
    "# model hyperparams\n",
    "n_epochs = 2\n",
    "batch_size = 4\n",
    "learning_rate_multiplier = 0.3\n",
    "# Custom data\n",
    "current_path = os.getcwd()\n",
    "training_file = os.path.abspath(os.path.join(current_path, 'data/training_data.jsonl'))\n",
    "validation_file = os.path.abspath(os.path.join(current_path, 'data/validation_data.jsonl'))\n",
    "assert os.path.exists(training_file) and os.path.exists(validation_file)\n",
    "# Upload to OpenAI\n",
    "train_uploader = openai.File.create(file=open(training_file, 'rb'), purpose='fine-tune')\n",
    "val_uploader = openai.File.create(file=open(validation_file, 'rb'), purpose='fine-tune')\n",
    "\n",
    "# config\n",
    "configs = {\n",
    "    'model': model,\n",
    "    'n_epochs': n_epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'learning_rate_multiplier': learning_rate_multiplier,\n",
    "    'training_file': train_uploader.id,\n",
    "    'validation_file': val_uploader.id\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\" Fine-tuning process \"\"\"\n",
    "# creation\n",
    "fine_tuner = openai.FineTune.create(**configs)\n",
    "fine_tuning_end = False\n",
    "fine_tuning_events = []\n",
    "while True:\n",
    "    late_event = openai.FineTune.retrieve(id=fine_tuner.id)['events'][-1]['message'] # OR: openai.FineTune.list_events(id=fine_tuner.id)\n",
    "    late_status = openai.FineTune.retrieve(id=fine_tuner.id)['status']\n",
    "    fine_tuning_end = (late_status == 'succeeded') or (late_status == 'failed')\n",
    "    if late_event not in fine_tuning_events:\n",
    "        fine_tuning_events.append(late_event)\n",
    "        print(f'[Info] current event: {late_event}')\n",
    "    if fine_tuning_end:\n",
    "        break\n",
    "    \n",
    "\"\"\" Inference\"\"\"\n",
    "fine_tuned_model = openai.FineTune.retrieve(id=fine_tuner.id).fine_tuned_model\n",
    "example_prompt = 'What is the capital of South Korea?->'\n",
    "example_response = openai.Completion.create(\n",
    "    model=fine_tuned_model,\n",
    "    prompt=example_prompt,\n",
    "    max_tokens=100,\n",
    "    temperature=0.5,\n",
    "    )\n",
    "# inference with example prompt\n",
    "print(f'Example response of {example_prompt} is \\n \\t {example_response[\"choices\"][0][\"text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
