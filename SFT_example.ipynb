{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of using of OpenAI's GPT through the API\n",
    "\n",
    "### Section: Supervised Fine-Tuning (SFT)\n",
    "\n",
    "#### Writer\n",
    "    Kunwoong Kim\n",
    "\n",
    "#### Created / Last edited\n",
    "    2023.06.21 / 2023.06.23\n",
    "\n",
    "#### Notes\n",
    "    Please be aware of the billing associated with using OpenAI's API!\n",
    "    This notebook is written based on:\n",
    "\n",
    "<https://www.indiehackers.com/post/how-to-fine-tune-a-gpt-3-model-using-python-with-your-own-data-for-improved-performance-198dfe51d6>\n",
    "\n",
    "<https://www.articulatepython.com/blog/finetune-openai-models>\n",
    "\n",
    "<https://www.datacamp.com/tutorial/fine-tuning-gpt-3-using-the-open-ai-api-and-python>\n",
    "\n",
    "<https://passwd.tistory.com/entry/Python-OpenAI-API-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "OpenAI API: create your API key\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "# API key\n",
    "openai.api_key = 'YOUR-API-KEY' # for sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] current event: Created fine-tune: ft-xk8trrS4H7aOySv6NGf0NR6r\n",
      "[Info] current event: Fine-tune costs $0.00\n",
      "[Info] current event: Fine-tune enqueued. Queue number: 0\n",
      "[Info] current event: Fine-tune started\n",
      "[Info] current event: Completed epoch 2/2\n",
      "[Info] current event: Uploaded model: curie:ft-idea-lab-seoul-national-university-2023-06-23-07-30-00\n",
      "[Info] current event: Fine-tune succeeded\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "GPT fine-tuning\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "\"\"\" Configuration \"\"\"\n",
    "# model engine\n",
    "model = 'curie'\n",
    "# model hyperparams\n",
    "n_epochs = 2\n",
    "batch_size = 4\n",
    "learning_rate_multiplier = 0.3\n",
    "# Custom data\n",
    "current_path = os.getcwd()\n",
    "training_file = os.path.abspath(os.path.join(current_path, 'data/training_data.jsonl'))\n",
    "validation_file = os.path.abspath(os.path.join(current_path, 'data/validation_data.jsonl'))\n",
    "assert os.path.exists(training_file) and os.path.exists(validation_file)\n",
    "# Upload to OpenAI\n",
    "train_uploader = openai.File.create(file=open(training_file, 'rb'), purpose='fine-tune')\n",
    "val_uploader = openai.File.create(file=open(validation_file, 'rb'), purpose='fine-tune')\n",
    "\n",
    "# config\n",
    "configs = {\n",
    "    'model': model,\n",
    "    'n_epochs': n_epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'learning_rate_multiplier': learning_rate_multiplier,\n",
    "    'training_file': train_uploader.id,\n",
    "    'validation_file': val_uploader.id\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\" Fine-tuning process \"\"\"\n",
    "# creation\n",
    "fine_tuner = openai.FineTune.create(**configs)\n",
    "fine_tuning_end = False\n",
    "fine_tuning_events = []\n",
    "while True:\n",
    "    late_event = openai.FineTune.retrieve(id=fine_tuner.id)['events'][-1]['message'] # OR: openai.FineTune.list_events(id=fine_tuner.id)\n",
    "    late_status = openai.FineTune.retrieve(id=fine_tuner.id)['status']\n",
    "    fine_tuning_end = (late_status == 'succeeded') or (late_status == 'failed')\n",
    "    if late_event not in fine_tuning_events:\n",
    "        fine_tuning_events.append(late_event)\n",
    "        print(f'[Info] current event: {late_event}')\n",
    "    if fine_tuning_end:\n",
    "        break\n",
    "    \n",
    "\"\"\" Inference\"\"\"\n",
    "fine_tuned_model = openai.FineTune.retrieve(id=fine_tuner.id).fine_tuned_model\n",
    "example_prompt = 'What is the capital of South Korea?->'\n",
    "example_response = openai.Completion.create(\n",
    "    model=fine_tuned_model,\n",
    "    prompt=example_prompt,\n",
    "    max_tokens=100,\n",
    "    temperature=0.5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example response of What is the capital of South Korea?-> is \n",
      " \t  Seoul, South Korea\n",
      "\n",
      "What is the capital of South Korea?-> Seoul, South Korea\n",
      "\n",
      "What is the capital of South Korea?-> Seoul, South Korea\n",
      "\n",
      "What is the capital of South Korea?-> Seoul, South Korea\n",
      "\n",
      "What is the capital of South Korea?-> Seoul, South Korea\n",
      "\n",
      "What is the capital of South Korea?-> Seoul, South Korea\n",
      "\n",
      "What is the capital of South Korea?-> Seoul, South Korea\n",
      "\n",
      "What is the capital\n"
     ]
    }
   ],
   "source": [
    "# inference with example prompt\n",
    "print(f'Example response of {example_prompt} is \\n \\t {example_response[\"choices\"][0][\"text\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
